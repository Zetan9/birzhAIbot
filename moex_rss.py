import feedparser
import re
import logging
import requests
from bs4 import BeautifulSoup
from datetime import datetime
from typing import List, Dict, Optional

logger = logging.getLogger(__name__)

RSS_URL = "https://rsshub.rss3.workers.dev/telegram/channel/moextrades"
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36'
}

def fetch_feed():
    try:
        response = requests.get(RSS_URL, headers=HEADERS, timeout=10)
        response.raise_for_status()
        feed = feedparser.parse(response.text)
        logger.info(f"RSS –∑–∞–≥—Ä—É–∂–µ–Ω, –∑–∞–ø–∏—Å–µ–π: {len(feed.entries)}")
        return feed
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ RSS: {e}")
        return None

def clean_html(html: str) -> str:
    """–£–¥–∞–ª—è–µ—Ç HTML-—Ç–µ–≥–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç."""
    soup = BeautifulSoup(html, 'html.parser')
    return soup.get_text(separator=' ')

def parse_signal_from_item(item) -> Optional[Dict]:
    title = item.get('title', '')
    description = item.get('description', '')
    link = item.get('link', '')
    pub_date = item.get('published', '')

    # –û—á–∏—â–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –æ—Ç HTML
    clean_text = clean_html(description)
    logger.debug(f"–ß–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç: {clean_text[:200]}")

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø–æ —ç–º–æ–¥–∑–∏ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ
    if 'üìà' in title or 'üü¢' in title:
        signal_type = 'bullish'
    elif 'üî¥' in title or 'üìâ' in title:
        signal_type = 'bearish'
    else:
        logger.debug("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø —Å–∏–≥–Ω–∞–ª–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
        return None

    # –¢–∏–∫–µ—Ä (–ø–æ—Å–ª–µ #)
    ticker_match = re.search(r'#([A-Z]+)', title)
    if not ticker_match:
        logger.debug("–ù–µ –Ω–∞–π–¥–µ–Ω —Ç–∏–∫–µ—Ä –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ")
        return None
    ticker = ticker_match.group(1)

    # –¶–µ–Ω–∞
    price_match = re.search(r'–¶–µ–Ω–∞:\s*([\d\.]+)', clean_text)
    price = float(price_match.group(1)) if price_match else None
    if not price:
        # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Ü–µ–Ω—É –≤ –¥—Ä—É–≥–æ–º —Ñ–æ—Ä–º–∞—Ç–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–æ—Å–ª–µ "–¶–µ–Ω–∞: <b>")
        price_match = re.search(r'–¶–µ–Ω–∞:.*?([\d\.]+)', description, re.DOTALL)
        price = float(price_match.group(1)) if price_match else None

    # –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ–Ω—ã ŒîP
    delta_p_match = re.search(r'ŒîP\s*([+-]?[\d\.]+)%', clean_text)
    delta_p = float(delta_p_match.group(1)) if delta_p_match else None

    # –ê–Ω–æ–º–∞–ª—å–Ω—ã–π –æ–±—ä—ë–º
    volume_match = re.search(r'–ê–Ω–æ–º–∞–ª—å–Ω—ã–π –æ–±—ä—ë–º:\s*([\d\.]+)([–ú–ö]?)', clean_text)
    volume = None
    if volume_match:
        val = float(volume_match.group(1))
        unit = volume_match.group(2)
        if unit == '–ú':
            volume = val * 1_000_000
        elif unit == '–ö':
            volume = val * 1_000
        else:
            volume = val

    # –ü—Ä–æ—Ü–µ–Ω—Ç –ø–æ–∫—É–ø–∫–∏/–ø—Ä–æ–¥–∞–∂–∏
    buy_match = re.search(r'–ü–æ–∫—É–ø–∫–∞:\s*(\d+)%', clean_text)
    sell_match = re.search(r'–ü—Ä–æ–¥–∞–∂–∞:\s*(\d+)%', clean_text)
    buy_pct = int(buy_match.group(1)) if buy_match else None
    sell_pct = int(sell_match.group(1)) if sell_match else None

    # –í—Ä–µ–º—è —Å–∏–≥–Ω–∞–ª–∞
    time_match = re.search(r'–í—Ä–µ–º—è:\s*([\d\.: ]+)', clean_text)
    if time_match:
        try:
            signal_time = datetime.strptime(time_match.group(1), '%d.%m.%Y %H:%M:%S')
        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤—Ä–µ–º–µ–Ω–∏: {e}")
            signal_time = datetime.now()
    else:
        signal_time = datetime.now()

    post_id = link.split('/')[-1] if link else None

    signal = {
        'id': post_id,
        'ticker': ticker,
        'type': signal_type,
        'price': price,
        'delta_p': delta_p,
        'volume': volume,
        'buy_pct': buy_pct,
        'sell_pct': sell_pct,
        'time': signal_time,
        'raw_text': description[:200]
    }
    logger.debug(f"–ù–∞–π–¥–µ–Ω —Å–∏–≥–Ω–∞–ª: {signal}")
    return signal

def fetch_signals(limit: int = 50) -> List[Dict]:
    feed = fetch_feed()
    if not feed:
        return []
    signals = []
    for entry in feed.entries[:limit]:
        sig = parse_signal_from_item(entry)
        if sig:
            signals.append(sig)
    logger.info(f"–ü–æ–ª—É—á–µ–Ω–æ {len(signals)} —Å–∏–≥–Ω–∞–ª–æ–≤ –∏–∑ RSS")
    return signals